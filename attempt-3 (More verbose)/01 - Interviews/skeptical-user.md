# Accessibility Interview: Skeptical User (Credibility Evaluator)

**Persona:** Jordan Reeves (Director of Product, B2B SaaS)  
**Website:** https://launchpadlab.com/  
**Date:** February 16, 2025  
**Task:** Find what LaunchPad Lab does and how to contact them—while evaluating credibility.  
**Testing Conditions:** Skeptical evaluator mindset. Two prior vendor engagements went poorly. Demands evidence, specifics, and verification paths.

---

## First-Person Narrative

I've been burned by agencies that looked good on the surface. Beautiful website, great testimonials—and then the project fell apart. So when I landed on LaunchPad Lab's homepage, I wasn't here to be impressed. I was here to dig. I need to understand exactly what they do, see proof of their work, and find a clear path to contact—without feeling like I'm walking into a sales funnel with no information. I'm researching them for a potential AI-integration project. Let's see what they give me.

**The hero told me they're "AI-centric digital product design and development."** Fine. That's a claim. But "AI-centric" is a buzzword until I see concrete examples. What does that mean? Do they build custom ML models? Integrate third-party APIs? Design AI-powered UX? The hero doesn't say. I scrolled. I found six service boxes—AI Automation, Web Apps, something about design, something about strategy. Each one had a "Learn more" link. Six identical "Learn more" links. I couldn't tell which service was which from the links list. That's a UX problem, but it also made me wonder: if they can't distinguish their own services clearly, how do they communicate with clients? Small thing. But it adds up.

**The client logos.** Dozens of them. Recognizable names. But no context. Which projects did they do for which client? A logo tells me they worked with someone. It doesn't tell me what they built, whether it succeeded, or whether I can verify it. I can't look up "we worked with Client X" without knowing what the engagement was. Logos without project context feel like decoration. Show me the work. Tell me the outcome.

**The statistics hit me next. "12+ Years in Business." "730+ Projects." "4.8 Rating."** Where do these come from? I looked for a source. Nothing. "4.8 rating"—on what platform? Google? Clutch? G2? From how many reviews? Ten? A thousand? I have no way to verify. "730+ projects"—who's counting? Over what period? Are we talking full builds or small engagements? These numbers are presented as proof. Without a source, they're just marketing. I've seen agencies inflate project counts by counting every tiny task. I've seen ratings from five reviews. Give me a link. Give me context. Otherwise I'm supposed to take your word for it. I don't.

**The award badges.** Seven of them. Clutch. Inc. 5000. Others I couldn't identify from the images. What does "Top Agency 2024" mean? Who gave it? What criteria? How many agencies were considered? I hovered. No tooltips. I looked for links. Nothing. Badges without context are vanity. They could mean something. They could mean nothing. I have no way to tell. A firm that's confident in their awards would explain them. "Clutch Top B2B Services Firm 2024—based on verified client reviews." That would help. As it stands, they're wallpaper.

**The testimonials.** I found them on the homepage and again on the Contact page—above the form, which is backwards. I came to contact them. I had to scroll past five long quotes first. But let's talk about the quotes themselves. "We always looked forward to our meetings because LaunchPad Lab was fun and easy to work with." That could apply to any agency. "I think everybody here has been really impressed and really happy with where the app is going." Vague. No client name. No project context. No measurable outcome. One quote stood out: "The first full year our system was in place, we saw a 7% increase in both online membership sales and general admission tickets." That's something. A number. An outcome. But who said it? Which client? Which project? I can't verify it. I can't look them up. And it's buried among four generic quotes. One substantive testimonial out of five isn't enough to build trust.

**The case studies.** I navigated to Work. Chicago Line Cruises—mobile-friendly ticketing site. Amplify Credit Union—website redesign, headless CMS, Salesforce, ADA compliance. Apex Leaders—investor advisor portal. The case study pages gave me project descriptions. What they built. Technologies used. But measurable outcomes? Chicago Line Cruises—did page load improve? By how much? Did conversion increase? Amplify—57,000 members mentioned, but what was the impact? Growth? Adoption? Apex Leaders—"streamlined operations," "enhanced engagement." How? Numbers? Before and after? The case studies read like marketing. They tell me what was built. They don't tell me whether it worked. I want "We reduced checkout abandonment by 23%." I want "Support tickets dropped 40% after launch." I got "We built a modern, clean design." That's not proof. That's a description.

**Services and process.** I went to the Services page. AI-focused digital product development. UX, design, strategy, development. The language was polished. But where's the process? How do they work? Discovery phase—how long? What deliverables? Typical engagement size? Timeline? Pricing? I found nothing. No "How we work" section. No "What to expect" guide. No indication of typical project scope or cost range. The only path forward is "Connect with an Expert." That's a CTA. It's not transparency. A firm that's confident in their process would explain it. "Step 1: Discovery call. Step 2: Proposal. Step 3: Kickoff." Something. "Contact us for a quote" with no context feels like a black box. I'm supposed to hand over my information and hope someone calls? What happens next? Response time? What do they need from me? The Contact page doesn't say.

**The contact path.** I found it. "Connect with an Expert" in the nav leads to the Contact page. There's a form. Name, email, company, message. And those five testimonials above it. No phone number visible. No email. No "We'll respond within 24 hours." No "Next step: discovery call." I could fill out the form. But I'd be doing it blind. I don't know what to expect. I don't know if they'll follow up. I don't know their typical engagement size or whether my project fits. That's not a clear path. That's a lead capture.

**Site quality.** I'll give them this: the site looks professional. Clean design. It loads. Navigation is straightforward—Work, Services, About, Connect with an Expert. I found what they do. I found how to contact them. The information is there. But the *substance* is thin. Buzzwords without examples. Statistics without sources. Badges without context. Testimonials that are mostly generic. Case studies without measurable outcomes. No process. No pricing. No expectation setting. For a director of product who's been burned twice, this doesn't build confidence. It triggers skepticism.

**What worked:** The value proposition is clear enough—AI-centric digital product design and development. I can articulate what they do. The contact path exists. One testimonial had a real number—7%. The case studies name real clients (Chicago Line Cruises, Amplify Credit Union, Apex Leaders)—I could look those up. The site looks professional. No broken links that I hit. The navigation is logical.

**What didn't work:** Unverifiable statistics. Award badges with no context. Four out of five testimonials are generic. Case studies lack measurable outcomes. No process documentation. No pricing or engagement expectations. "Contact Us" as the only path with no explanation of what happens next. Buzzwords ("AI-centric," "digital transformation") without concrete examples. Testimonials above the form—poor UX and feels like they're selling before I can act. I can't verify the 4.8 rating. I can't verify the 730+ projects. I'm supposed to trust claims without evidence. I won't.

**Would I contact them?** Maybe. I found the path. I could fill out the form. But I'd do it with low confidence. If I'm evaluating multiple agencies, and one has case studies with real numbers, testimonials with attribution, a clear process section, and statistics with sources—I'll choose that one. LaunchPad Lab has the structure. They don't have the substance. For a skeptical evaluator, substance is everything.

**Rating: 2.5 out of 5.** I completed the task. I found what they do and how to contact them. The site is professional. But the credibility gaps are significant. Unverifiable statistics. Context-free badges. Generic testimonials. Case studies without outcomes. No process or pricing transparency. One good testimonial and real client names in case studies keep it from a 2. A 3 would mean I felt I could verify some claims and had a sense of their process. A 2.5 means I got the basics, but I wouldn't recommend them to a colleague without caveats. They need more evidence. More transparency. More specifics. Until then, I'm not convinced.

**Bottom line:** I can complete my task. I cannot build trust from what they've given me.

---

## Additional Reflections

**On statistics:** "730+ projects" and "4.8 rating" could be legitimate. But without a source, they're meaningless. Link to Clutch. Link to a methodology page. "4.8/5 from 47 verified reviews on Clutch." That would help. As it stands, I have no way to check. I've seen agencies claim "500+ projects" when they count every support ticket. Be transparent. Show your work.

**On award badges:** Seven badges. I recognized Clutch and Inc. 5000. The rest—no idea. Add tooltips. Add a link to an "Awards" page that explains each one. "Clutch Top B2B Services Firm 2024—awarded based on verified client reviews and market presence." "Inc. 5000 2023—ranked #2,847 for growth." Context transforms decoration into evidence.

**On testimonials:** One quote had a measurable outcome. Four did not. Prioritize substantive quotes. Name the client (with permission) and the project type. "Sarah Chen, VP of Product at Amplify Credit Union: 'The first full year our system was in place, we saw a 7% increase in both online membership sales and general admission tickets.'" That's verifiable. That's proof. The generic "fun to work with" quotes don't help. Cut them or move them down.

**On case studies:** Chicago Line Cruises, Amplify, Apex Leaders—good. Real names. But add outcomes. "Page load time reduced by 40%." "Checkout conversion increased 15%." "Support tickets decreased 30%." Before and after. Numbers. If you don't have them, say why. "Results pending client approval." Something. Case studies without outcomes read like marketing. Case studies with outcomes read like proof.

**On process and pricing:** I don't need exact pricing. I need expectations. "Typical engagements range from 3–6 months." "Discovery phase: 2 weeks, deliverable: strategy document." "We respond to contact form submissions within 24 hours." A "How we work" section. A "What to expect" guide. Transparency builds trust. Vagueness triggers skepticism.

**On the Contact page:** Put the form first. Or add "Skip to contact form." Tell me what happens next. "We'll reach out within 24 hours to schedule a discovery call." "Please include: project type, timeline, and budget range." Set expectations. Reduce friction. Right now it feels like I'm handing over my information with no idea what comes next.

**On verification:** I could look up Chicago Line Cruises, Amplify Credit Union, Apex Leaders. I could search for LaunchPad Lab on Clutch. The site gives me enough to start. But it doesn't make it easy. Link to your Clutch profile. Link to case study clients (if they have public sites). Make verification a one-click path. The easier it is to verify, the more I'll trust.

**On the "Connect with an Expert" CTA:** It's clear. I knew where to go. But "expert" is another buzzword. Expert in what? The nav doesn't say "Contact" or "Get a quote"—it says "Connect with an Expert." That's sales language. I prefer straightforward. "Contact" or "Request a proposal" tells me what I'm doing. "Connect with an Expert" feels like I'm being sold to before I've decided. Small thing. But tone matters when you're building trust.

**On the About page:** I visited it. Team, culture, maybe origin story. I didn't document it in depth—my focus was credibility, not culture. But for a skeptical user, the About page could reinforce trust if it showed real people, real experience, real expertise. LinkedIn links for key team members. Years of experience. Specific domains. If the About page is generic ("we're passionate about digital"), it doesn't help. If it's substantive, it could offset some of the homepage gaps.

**On comparison to other agencies:** I've evaluated dozens. The ones that win my business have: case studies with numbers, testimonials with names and outcomes, a clear process section, statistics with sources, and a contact path that tells me what to expect. LaunchPad Lab has the surface. They don't have the depth. I'd put them in the "maybe" pile—worth a conversation if I'm desperate, but not my first choice. Fix the gaps, and they'd move up.

**On what would change my mind:** If I came back and saw: "4.8/5 from 47 Clutch reviews" with a link, case studies with "conversion up 15%" or "load time down 40%," a "How we work" section, and "We respond within 24 hours" on the Contact page—I'd take them seriously. It's not a huge lift. It's the difference between "marketing" and "proof."

**On the AI angle:** They bill themselves as AI-centric. For my project—AI integration—that matters. But I didn't see concrete AI examples. No "We built a RAG-powered search" or "We integrated GPT for document summarization." If they're AI-centric, the case studies and services should show it. Right now it's a label, not a demonstration. I'd need to ask in a discovery call—but the site should answer that question before I pick up the phone.

**Final thoughts:** I've been burned by agencies. I've learned to demand evidence. LaunchPad Lab has the bones—clear value prop, real client names, professional site. But they're thin on proof. Statistics without sources. Badges without context. Generic testimonials. Case studies without outcomes. No process. No pricing. No "what happens next." For a skeptical evaluator, that's not enough. Fix those gaps, and they'd be in the running. As it stands, I'd hesitate.

---

*Interview conducted as Jordan Reeves, skeptical evaluator persona. Task: Find what LaunchPad Lab does and how to contact them—while assessing credibility. Completed with significant trust gaps. Rating: 2.5/5.*

*— Jordan Reeves*

---

*Note: Testing performed from credibility-evaluation perspective. Homepage, Contact, Services, About, and Work pages evaluated. Focus: unverifiable statistics, context-free badges, generic testimonials, case study substance, process/pricing transparency, and contact path clarity. Persona demands evidence over claims and judges professionalism by transparency and verifiability. Task completed; credibility gaps documented.*
